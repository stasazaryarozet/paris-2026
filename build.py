#!/usr/bin/env python3
"""
–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç content.js –∏–∑ WEBSITE_CONTENT.md
–ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫ –ø—Ä–∞–≤–¥—ã: WEBSITE_CONTENT.md

–í–ê–ñ–ù–û: –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —á–∏—Å—Ç—ã–π JavaScript (–±–µ–∑ –∫–∞–≤—ã—á–µ–∫ —É –∫–ª—é—á–µ–π)
"""

import re
from pathlib import Path

def parse_frontmatter(content):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç YAML frontmatter"""
    match = re.match(r'^---\n(.*?)\n---\n', content, re.DOTALL)
    if not match:
        return {}, content
    
    fm_text = match.group(1)
    body = content[match.end():]
    
    meta = {}
    for line in fm_text.split('\n'):
        if ':' in line:
            key, value = line.split(':', 1)
            meta[key.strip()] = value.strip().strip('"')
    
    return meta, body

def js_string(s):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç —Å—Ç—Ä–æ–∫—É –≤ JS string literal"""
    return '"' + s.replace('\\', '\\\\').replace('"', '\\"').replace('\n', '\\n') + '"'

def js_object(data, indent=2):
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç JS –æ–±—ä–µ–∫—Ç (–ë–ï–ó –∫–∞–≤—ã—á–µ–∫ —É –∫–ª—é—á–µ–π)"""
    if isinstance(data, dict):
        lines = []
        for key, value in data.items():
            value_str = js_object(value, indent + 2)
            lines.append(' ' * indent + f'{key}: {value_str}')
        return '{\n' + ',\n'.join(lines) + '\n' + ' ' * (indent - 2) + '}'
    elif isinstance(data, list):
        if not data:
            return '[]'
        lines = []
        for item in data:
            lines.append(' ' * indent + js_object(item, indent + 2))
        return '[\n' + ',\n'.join(lines) + '\n' + ' ' * (indent - 2) + ']'
    elif isinstance(data, str):
        return js_string(data)
    elif isinstance(data, bool):
        return 'true' if data else 'false'
    elif data is None:
        return 'null'
    else:
        return str(data)

def parse_content(md_path):
    """–ü–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ WEBSITE_CONTENT.md"""
    content = Path(md_path).read_text(encoding='utf-8')
    meta, body = parse_frontmatter(content)
    
    data = {}
    
    # HERO ‚Äî –ü–ï–†–í–´–ô (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ)
    hero_match = re.search(r'^# (.+?)\n\n\*\*Subtitle:\*\*\s*\n(.+?)\n\n\*\*Dates:\*\* (.+?)\n\*\*Group:\*\* (.+?)\n\*\*Price:\*\* (.+?)(?:\n|$)', body, re.DOTALL)
    if hero_match:
        title_raw = hero_match.group(1).strip()
        title_html = title_raw.replace('<span class="hero-accent">', "<span style='font-size: 1.3em; font-weight: 800;'>")
        
        subtitle_raw = hero_match.group(2).strip()
        subtitle_html = subtitle_raw.replace('\n', '<br>')
        
        data['hero'] = {
            'title': title_html,
            'subtitle': subtitle_html,
            'dates': hero_match.group(3).strip(),
            'group': hero_match.group(4).strip(),
            'price': hero_match.group(5).strip()
        }
    else:
        # Fallback –∏–∑ –∫–æ–º–º–∏—Ç–∞
        data['hero'] = {
            'title': "–ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω—ã–π –ø–æ—á–µ—Ä–∫ –∞—Ä-–¥–µ–∫–æ.<br><span style='font-size: 1.3em; font-weight: 800;'>100 –ª–µ—Ç</span>.",
            'subtitle': "4 –¥–Ω—è —Å –∫—É—Ä–∞—Ç–æ—Ä–∞–º–∏.<br>–§–∞–∫—Ç—É—Ä—ã, –º–∞—Ç–µ—Ä–∏–∞–ª—ã, –∞—Ç–º–æ—Å—Ñ–µ—Ä–∞.<br>–¢–æ, —á—Ç–æ –Ω–µ –≤–∏–¥–Ω–æ –≤ –ø—É–±–ª–∏–∫–∞—Ü–∏—è—Ö.",
            'dates': "15‚Äì18+ —è–Ω–≤–∞—Ä—è 2026",
            'group': "–¥–æ 12 —á–µ–ª–æ–≤–µ–∫",
            'price': "1 550 ‚Ç¨"
        }
    
    # META ‚Äî –í–¢–û–†–û–ô
    data['meta'] = {
        'title': meta.get('title', ''),
        'description': meta.get('description', ''),
        'keywords': meta.get('keywords', ''),
        'ogTitle': meta.get('og_title', ''),
        'ogDescription': meta.get('og_description', ''),
        'ogImage': meta.get('og_image', ''),
        'url': meta.get('og_url', '')
    }
    
    # PROGRAM
    data['program'] = {'intro': []}
    prog_match = re.search(r'## –ü—Ä–æ–≥—Ä–∞–º–º–∞\n\n(.+?)---', body, re.DOTALL)
    if prog_match:
        intro_text = prog_match.group(1).strip()
        for para in intro_text.split('\n\n'):
            para = para.strip()
            if para.startswith('>'):
                text = para.strip('> ').strip('*').strip()
                data['program']['intro'].append({
                    'type': 'highlight',
                    'text': text
                })
            elif para:
                data['program']['intro'].append(para)
    
    # DAYS
    data['days'] = []
    day_pattern = r'## (–î–ï–ù–¨ [IVX]+) ‚Ä¢ (.+?)\n### (.+?)(?:\n\*\*–¢–µ–º–∞:\*\* (.+?))?\n\n(.*?)(?=\n---|\n## [–ö–ß]|$)'
    
    for match in re.finditer(day_pattern, body, re.DOTALL):
        day_num, date, title, theme_optional, locations_text = match.groups()
        theme = theme_optional if theme_optional else ""
        
        locations = []
        location_pattern = r'\*\*(.+?)\*\*\s*\n(.+?)(?=\n\*\*|\n---|\n## |$)'
        for loc_match in re.finditer(location_pattern, locations_text, re.DOTALL):
            name, desc = loc_match.groups()
            desc_clean = desc.strip().replace('\n\n', '\n')
            locations.append({
                'name': name.strip(),
                'description': desc_clean
            })
        
        day_data = {
            'number': day_num,
            'date': date.strip(),
            'title': title.strip(),
            'theme': theme.strip(),
            'locations': locations
        }
        
        evening_match = re.search(r'\*\*–í–µ—á–µ—Ä:\*\* (.+?)(?=\n|$)', locations_text)
        if evening_match:
            day_data['evening'] = evening_match.group(1).strip()
        
        data['days'].append(day_data)
    
    # CURATORS
    data['curators'] = []
    curators_section = re.search(r'## –ö—É—Ä–∞—Ç–æ—Ä—ã\n\n(.+?)---', body, re.DOTALL)
    if curators_section:
        curator_pattern = r'### (.+?)\n\*\*(.+?)\*\*\n\n(.*?)(?=\n### |\n---|\Z)'
        for match in re.finditer(curator_pattern, curators_section.group(1), re.DOTALL):
            name, role, bio_text = match.groups()
            bio = [line.strip('‚Ä¢ ').strip() for line in bio_text.strip().split('\n') if line.strip()]
            data['curators'].append({
                'name': name.strip(),
                'role': role.strip(),
                'bio': bio
            })
    
    # INCLUSIONS
    data['inclusions'] = []
    incl_section = re.search(r'## –ß—Ç–æ –≤–∫–ª—é—á–µ–Ω–æ\n\n(.+?)$', body, re.DOTALL)
    if incl_section:
        incl_pattern = r'\*\*([‚úì‚úóüí∂]) (.+?)\*\*\s*\n(.+?)(?=\n\*\*|$)'
        for match in re.finditer(incl_pattern, incl_section.group(1), re.DOTALL):
            icon, title, desc = match.groups()
            
            inc_data = {
                'icon': icon.strip(),
                'title': title.strip(),
                'description': desc.strip()
            }
            
            if 'üí∂' in icon:
                price_match = re.search(r'–°—Ç–æ–∏–º–æ—Å—Ç—å: (.+)', title)
                if price_match:
                    inc_data['price'] = price_match.group(1).strip()
                    inc_data['title'] = '–°—Ç–æ–∏–º–æ—Å—Ç—å'
            
            data['inclusions'].append(inc_data)
    
    return data

def generate_content_js(data):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç content.js —Å —á–∏—Å—Ç—ã–º JS —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–æ–º"""
    js = "const CONTENT = " + js_object(data, 2) + ";\n"
    return js

def main():
    print("üî® –ì–µ–Ω–µ—Ä–∞—Ü–∏—è content.js –∏–∑ WEBSITE_CONTENT.md...")
    
    data = parse_content('WEBSITE_CONTENT.md')
    js = generate_content_js(data)
    
    Path('content.js').write_text(js, encoding='utf-8')
    
    print("‚úÖ content.js –æ–±–Ω–æ–≤–ª—ë–Ω –∏–∑ WEBSITE_CONTENT.md")
    print("   ‚Ä¢ –ò—Å—Ç–æ—á–Ω–∏–∫ –ø—Ä–∞–≤–¥—ã: WEBSITE_CONTENT.md")
    print("   ‚Ä¢ content.js ‚Äî –∞–≤—Ç–æ–≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è, –Ω–µ —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –≤—Ä—É—á–Ω—É—é")
    print("   ‚Ä¢ –ß–∏—Å—Ç—ã–π JS —Å–∏–Ω—Ç–∞–∫—Å–∏—Å (–±–µ–∑ –∫–∞–≤—ã—á–µ–∫ —É –∫–ª—é—á–µ–π)")

if __name__ == '__main__':
    main()
